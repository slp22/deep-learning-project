{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slp22/deep-learning-project/blob/main/dl_diabetic_retinopathy_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74975ac3"
      },
      "source": [
        "#### Deep Learning | Model\n",
        "\n",
        "# Diabetic Retinopathy<a id='top'></a> "
      ],
      "id": "74975ac3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "HYTw2GEqeY6s"
      },
      "id": "HYTw2GEqeY6s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64179b94"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, shutil\n",
        "import pandas as pd\n",
        "import pathlib as Path\n",
        "import pickle\n",
        "import PIL\n",
        "import random\n",
        "import seaborn as sns\n",
        "import sklearn as sk\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import zipfile\n",
        "\n",
        "from glob import glob\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "from keras.applications import VGG16\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, InputLayer, GlobalAveragePooling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image as IMG\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.utils import to_categorical\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "%pylab inline\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_formats = ['retina']  # or svg\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "sns.set(context='notebook', style='whitegrid')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(\"Matplotlib version:\", matplotlib.__version__)\n",
        "print(\"Numpy version:\", np.__version__)\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Keras Version:\", tf.keras.__version__)\n",
        "print(\"Scikit-learn version:\", sk.__version__)\n"
      ],
      "id": "64179b94"
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://colab.research.google.com/notebooks/pro.ipynb#scrollTo=23TOba33L4qf\n",
        "# gpu_info = !nvidia-smi\n",
        "# gpu_info = '\\n'.join(gpu_info)\n",
        "# if gpu_info.find('failed') >= 0:\n",
        "#   print('Not connected to a GPU')\n",
        "# else:\n",
        "#   print(gpu_info)"
      ],
      "metadata": {
        "id": "C_-vF_CnwhKa"
      },
      "id": "C_-vF_CnwhKa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 | Research Design\n"
      ],
      "metadata": {
        "id": "qXbzNcqI-At3"
      },
      "id": "qXbzNcqI-At3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Research Question:** How well can a neural network diagnose diabetic retinopathy from a retinal image?\n",
        "* **Impact Hypothesis:** *The client, the [National Eye Institute](https://www.nei.nih.gov/), part of the National Institutes of Health, wants a model that can quickly identify [diabetic retinopathy](https://www.nei.nih.gov/learn-about-eye-health/eye-conditions-and-diseases/diabetic-retinopathy) in patients participating in early phase [clinical trials](https://iovs.arvojournals.org/article.aspx?articleid=2565675).*\n",
        "* **Data source:** Personal Key Indicators of Heart Disease, n=319,795\n",
        "* **Error metric:** Accruary for model iteratoins, precision and recall for final model\n",
        "\n",
        "* **Data Dictionary:**\n",
        "  * Classes = 5 stages of diabetic retinopathy):\n",
        "    * **Normal eye**\n",
        "    * **Mild** Nonproliferative Retinopathy: Microaneurysms are visbile, small areas of balloon-like swelling in the retina's tiny blood vessels.\n",
        "    * **Moderate** Nonproliferative Retinopathy: Some blood vessels that nourish the retina are blocked.\n",
        "    * **Severe** Nonproliferative Retinopathy: More blocked blood vessels, depriving several areas of the retina of blood supply; retina sends signals to the body to grow new blood vessels for nourishment.\n",
        "    * **Proliferative** Retinopathy: Advanced stage; new blood vessels are abnormal and fragile; grow along the retina and along the surface of the clear, vitreous gel that fills the inside of the eye.\n"
      ],
      "metadata": {
        "id": "YV4bxudG-LG6"
      },
      "id": "YV4bxudG-LG6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d38894c8"
      },
      "source": [
        "## 2 | Dataset: [Diabetic Retinopathy Retinal Images](https://www.kaggle.com/datasets/sovitrath/diabetic-retinopathy-2015-data-colored-resized)"
      ],
      "id": "d38894c8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dataset from Kaggle"
      ],
      "metadata": {
        "id": "XLR-rZUhBcDS"
      },
      "id": "XLR-rZUhBcDS"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "3uJyuCs9jkJ7",
        "outputId": "fea011d7-9170-4c64-898d-dae3a9902cef"
      },
      "id": "3uJyuCs9jkJ7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-02f5f31d-a3d3-450d-8762-859d26074894\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-02f5f31d-a3d3-450d-8762-859d26074894\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"sandralparedes\",\"key\":\"746c1c655d0796973a3d3552fbcc97a5\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXLwZ2Vnn7ge",
        "outputId": "d65c5781-0ad5-4cbd-b43d-43ce89ca9a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "GXLwZ2Vnn7ge"
    },
    {
      "cell_type": "code",
      "source": [
        "# assign to directory \n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ],
      "metadata": {
        "id": "As3njbbDmjAY"
      },
      "id": "As3njbbDmjAY",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset from kaggle\n",
        "! kaggle datasets download -d sovitrath/diabetic-retinopathy-2015-data-colored-resized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD2q1R_8movA",
        "outputId": "36d6397a-f54a-4d4a-8b76-5dedc112624e"
      },
      "id": "jD2q1R_8movA",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "diabetic-retinopathy-2015-data-colored-resized.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip kaggle file\n",
        "zip_ref = zipfile.ZipFile('diabetic-retinopathy-2015-data-colored-resized.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "8bszkBF7ndyj"
      },
      "id": "8bszkBF7ndyj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "678fce99"
      },
      "source": [
        "## 3 | Exploratory Data Analysis"
      ],
      "id": "678fce99"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data size and classes"
      ],
      "metadata": {
        "id": "k3K6dIVTA85Q"
      },
      "id": "k3K6dIVTA85Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# show number of classes and images\n",
        "source_images_path = '/tmp/colored_images/colored_images/'\n",
        "extracted_directories_path = os.listdir(source_images_path)\n",
        "\n",
        "for image_directory in extracted_directories_path:\n",
        "  print(image_directory, len(os.listdir(os.path.join(source_images_path, image_directory))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Wqza8h6nqEY",
        "outputId": "f8c5e7b7-9fe1-44a7-f8d8-df4de5290c00"
      },
      "id": "5Wqza8h6nqEY",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Severe 873\n",
            "Moderate 5292\n",
            "Proliferate_DR 708\n",
            "No_DR 25810\n",
            "Mild 2443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/tmp/colored_images/colored_images'\n",
        "dataframe = {'image_path':[],'diagnosis':[]}\n",
        "\n",
        "for diagnosis in os.listdir(filepath):\n",
        "    print(diagnosis)\n",
        "    if diagnosis != 'colored_images':        \n",
        "        for image in os.listdir(filepath +\"/\"+diagnosis):\n",
        "            if image != 'Dataset':\n",
        "                dataframe['image_path'].append(filepath +\"/\"+diagnosis+\"/\"+ image)\n",
        "                dataframe['diagnosis'].append(diagnosis)\n",
        "dataframe = pd.DataFrame(dataframe)  \n",
        "dataframe.info()\n",
        "dataframe.head(2)"
      ],
      "metadata": {
        "id": "Vs7otXFJke-S"
      },
      "id": "Vs7otXFJke-S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SYJaUP4H-Cs"
      },
      "outputs": [],
      "source": [
        "# distribution of five diagnosis classes in order of severity of disease\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.barplot(dataframe.diagnosis.value_counts().index,\n",
        "            dataframe.diagnosis.value_counts(),\n",
        "            palette=None)\n",
        "plt.title(\"Distribution of Diabetic Retinopahty Diagnosis Classes\")\n",
        "plt.xlabel(\"Diagnosis\")\n",
        "plt.ylabel(\"Frequency\");\n"
      ],
      "id": "9SYJaUP4H-Cs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preview data"
      ],
      "metadata": {
        "id": "OGGX9W-lzlMS"
      },
      "id": "OGGX9W-lzlMS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wM6uskkH-Cs"
      },
      "outputs": [],
      "source": [
        "# view one healthy eye image\n",
        "\n",
        "path = '/tmp/colored_images/colored_images/No_DR/10003_left.png'\n",
        "\n",
        "healthy_image = tf.keras.preprocessing.image.load_img(\n",
        "   path,\n",
        "   grayscale=False, \n",
        "   color_mode=\"rgb\", \n",
        "  #  target_size=(256, 256),\n",
        "   interpolation=\"nearest\")\n",
        "\n",
        "print('No Diabetic Retinopthy')\n",
        "print('Datatype:', type(healthy_image))\n",
        "healthy_image \n"
      ],
      "id": "5wM6uskkH-Cs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdQHTkYEH-Cs"
      },
      "outputs": [],
      "source": [
        "# view one proliferate DR image (most advanced stage of disease)\n",
        "\n",
        "path = '/tmp/colored_images/colored_images/Proliferate_DR/10017_left.png'\n",
        "\n",
        "proliferate_image = tf.keras.preprocessing.image.load_img(\n",
        "   path,\n",
        "   grayscale=False, \n",
        "   color_mode=\"rgb\", \n",
        "  #  target_size=(256, 256), \n",
        "   interpolation=\"nearest\")\n",
        "\n",
        "print('Proliferate Diabetic Retinopthy')\n",
        "print('Datatype:', type(proliferate_image))\n",
        "proliferate_image \n"
      ],
      "id": "jdQHTkYEH-Cs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Summary: n = 35,126;  unbalanced classes**"
      ],
      "metadata": {
        "id": "HRx23uUVzhLD"
      },
      "id": "HRx23uUVzhLD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 | Validation"
      ],
      "metadata": {
        "id": "dGB1VbycEzd-"
      },
      "id": "dGB1VbycEzd-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create test and train folders, split data, and move into class folders"
      ],
      "metadata": {
        "id": "RoEREXfi_1bd"
      },
      "id": "RoEREXfi_1bd"
    },
    {
      "cell_type": "code",
      "source": [
        "# set up for train/test split\n",
        "\n",
        "# DO NOT RUN ##### shutil.rmtree('/tmp/raw_data/train/')\n",
        "# To re-run uncomment here\n",
        "\n",
        "temp_path = '/tmp'\n",
        "raw_data_dir_name = 'raw_data'\n",
        "\n",
        "train_data_dir_name = 'train'\n",
        "test_data_dir_name = 'test'\n",
        "raw_data_directories = [train_data_dir_name, test_data_dir_name]\n",
        "\n",
        "images_path =  os.path.join(temp_path, raw_data_dir_name)\n",
        "tmp_directories = os.listdir(temp_path)\n",
        "\n",
        "def build_raw_data_directory(parent, directory):\n",
        "  dir_path = os.path.join(parent, directory)\n",
        "  os.mkdir(dir_path)\n",
        "  for dir in extracted_directories_path:\n",
        "    os.mkdir(os.path.join(dir_path, dir))\n",
        "\n",
        "if raw_data_dir_name not in tmp_directories:\n",
        "  os.mkdir(images_path)\n",
        "  for directory in raw_data_directories:\n",
        "    build_raw_data_directory(images_path, directory)\n",
        "else:\n",
        "  print(raw_data_dir_name, \" already exist\")\n",
        "  images_path_directories = os.listdir(images_path)\n",
        "  for directory in raw_data_directories:\n",
        "    if directory not in images_path_directories:\n",
        "      build_raw_data_directory(images_path, directory)"
      ],
      "metadata": {
        "id": "kzKM7y_dOIkG"
      },
      "id": "kzKM7y_dOIkG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## split data into train/test folders\n",
        "## To re-run uncomment here\n",
        "\n",
        "distribution = 0.2\n",
        "\n",
        "raw_data_path = os.path.join(temp_path, raw_data_dir_name)\n",
        "test_data_path_root = os.path.join(raw_data_path, test_data_dir_name)\n",
        "train_data_path_root = os.path.join(raw_data_path, train_data_dir_name)\n",
        "\n",
        "data_dirs = os.listdir(source_images_path)\n",
        "\n",
        "for dir in data_dirs:\n",
        "  path = os.path.join(source_images_path, dir)\n",
        "  test_data_path = os.path.join(test_data_path_root, dir)\n",
        "  train_data_path = os.path.join(train_data_path_root, dir)\n",
        "  images = os.listdir(path)\n",
        "  print(path, test_data_path)\n",
        "  for image in images:\n",
        "    random_number = random.uniform(0, 1)\n",
        "    is_test_image = random_number < distribution\n",
        "    source_image_path = os.path.join(path, image)\n",
        "    # shutil.copy(src, dst)\n",
        "    if is_test_image:\n",
        "      shutil.copy(source_image_path, test_data_path)\n",
        "      # print(source_image_path, \"goes to test\", test_data_path)\n",
        "    else:\n",
        "      shutil.copy(source_image_path, train_data_path)\n",
        "      # print(source_image_path, \"goes to train\", train_data_path)\n",
        "\n",
        "test_data_path_root = os.path.join(raw_data_path, test_data_dir_name)\n",
        "train_data_path_root = os.path.join(raw_data_path, train_data_dir_name)\n",
        "\n",
        "test_dirs = os.listdir(test_data_path_root)\n",
        "train_dirs = os.listdir(train_data_path_root)\n",
        "\n",
        "for dir in test_dirs:\n",
        "  path = os.path.join(test_data_path_root, dir)\n",
        "  files = os.listdir(path)\n",
        "  print(path, len(files))\n",
        "\n",
        "for dir in train_dirs:\n",
        "  path = os.path.join(train_data_path_root, dir)\n",
        "  files = os.listdir(path)\n",
        "  print(path, len(files))"
      ],
      "metadata": {
        "id": "C-530XeBUQXs"
      },
      "id": "C-530XeBUQXs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train (80%) and test (20%) folders**"
      ],
      "metadata": {
        "id": "-JMyihpQ_xwD"
      },
      "id": "-JMyihpQ_xwD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 | Baseline "
      ],
      "metadata": {
        "id": "DL1eAZLI4WhQ"
      },
      "id": "DL1eAZLI4WhQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Deep Learning Model: Logistic Regression"
      ],
      "metadata": {
        "id": "NTEDyxmg-dlV"
      },
      "id": "NTEDyxmg-dlV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set up data for logistic regression\n",
        "Code adapted from [sdblass](https://github.com/sdblass/Metis_coursework/blob/master/6_Deep_Learning/2_baseline_model.ipynb)"
      ],
      "metadata": {
        "id": "Sn8eVz_kgInL"
      },
      "id": "Sn8eVz_kgInL"
    },
    {
      "cell_type": "code",
      "source": [
        "# create raw_data_small set to use in logistic regression model\n",
        "original_raw_data_path = '/tmp/raw_data'\n",
        "raw_data_copy = '/tmp/raw_data_small'\n",
        "shutil.copytree(original_raw_data_path, raw_data_copy)\n",
        "\n",
        "raw_data_copy_test_path = '/tmp/raw_data_small/test'\n",
        "raw_data_copy_train_path = '/tmp/raw_data_small/train'\n",
        "\n",
        "# cull to keep 200 images from each class in raw_data_small\n",
        "paths_to_reduce_images = [raw_data_copy_test_path, raw_data_copy_train_path]\n",
        "\n",
        "for path in paths_to_reduce_images:\n",
        "  dir_names = os.listdir(path)\n",
        "  for dir_name in dir_names:\n",
        "    images_path = os.path.join(path, dir_name)\n",
        "    files = os.listdir(images_path)\n",
        "    for index, file in enumerate(files):\n",
        "      if index >= 200:\n",
        "        file_path = os.path.join(images_path, file)\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "id": "RHBb1z_yzG54"
      },
      "id": "RHBb1z_yzG54",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/tmp/raw_data_small/train'\n",
        "retinas = os.listdir(root)\n",
        "retinas = [retina for retina in retinas if retina[0]!='.']"
      ],
      "metadata": {
        "id": "iWrBVEXogH0b"
      },
      "id": "iWrBVEXogH0b",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert image to 1D vector\n",
        "test_img_path = os.listdir(root+f'/{retinas[0]}')[0]\n",
        "test_img_path = root+f'/{retinas[0]}' + f'/{test_img_path}'\n",
        "test_img = Image.open(test_img_path)"
      ],
      "metadata": {
        "id": "RgbqnyJfgIDD"
      },
      "id": "RgbqnyJfgIDD",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num pixels\n",
        "dimension = np.array(test_img).reshape(-1).shape[0]\n",
        "dimension"
      ],
      "metadata": {
        "id": "zQhsHuochNrz"
      },
      "id": "zQhsHuochNrz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to count images\n",
        "def image_count(num_diagnoses, root): \n",
        "  num_images = 0\n",
        "  for i, retina in enumerate(retinas):\n",
        "    if i == num_diagnoses: break\n",
        "    num_images += len(os.listdir(root + f'/{retina}'))\n",
        "  return num_images"
      ],
      "metadata": {
        "id": "f-70Vh6uhNwa"
      },
      "id": "f-70Vh6uhNwa",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num images in raw_data_small; 5 classes (diagnoses) \n",
        "image_count(5, root) "
      ],
      "metadata": {
        "id": "Gbka11SphOJQ"
      },
      "id": "Gbka11SphOJQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # initialize 2D matrix with dimensions equal to num of images times num of pixels\n",
        "# image_repo = np.zeros([image_count(5, root), dimension])\n",
        "# image_repo"
      ],
      "metadata": {
        "id": "zBpX0-L2hOJ7"
      },
      "id": "zBpX0-L2hOJ7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to vectorize images in raw_data_small/train\n",
        "def img_vectorization(num_diagnoses, root):\n",
        "  image_repo = np.zeros([image_count(num_diagnoses, root), dimension])\n",
        "  count = 0\n",
        "  diagnosis = []\n",
        "  for i, retina in enumerate(retinas):\n",
        "    images = os.listdir(root + f'/{retina}')\n",
        "    for image in images:\n",
        "      img = Image.open(root + f'/{retina}' + f'/{image}')\n",
        "      row = np.array(img).reshape(-1)\n",
        "      image_repo[count, :] = row\n",
        "      diagnosis.append(retina)\n",
        "      img.close()\n",
        "      count += 1\n",
        "    if i == num_diagnoses - 1: \n",
        "      return image_repo, diagnosis\n",
        "  return image_repo, diagnosis\n",
        "# print(image_repo.shape)"
      ],
      "metadata": {
        "id": "SNFKMG6dhOKp"
      },
      "id": "SNFKMG6dhOKp",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train_dx = img_vectorization(5, root)"
      ],
      "metadata": {
        "id": "qQRvaQwi5pik"
      },
      "id": "qQRvaQwi5pik",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEMWXtdV8Up8",
        "outputId": "256b9ef3-238f-4cd5-a5f1-65f0a2b6c355"
      },
      "id": "JEMWXtdV8Up8",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('X train shape:', X_train.shape)\n",
        "print('y train (dx) length:', len(y_train_dx))"
      ],
      "metadata": {
        "id": "FFGMNNW88U0m"
      },
      "id": "FFGMNNW88U0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize raw_data_small/test data\n",
        "root_test = '/tmp/raw_data_small/test'\n",
        "X_test, y_test_dx = img_vectorization(5, root_test)"
      ],
      "metadata": {
        "id": "-NqRmotw8aYC"
      },
      "id": "-NqRmotw8aYC",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)\n",
        "print(X_test.shape)\n",
        "print(len(y_test_dx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0w2QZSD8yKD",
        "outputId": "12cf8215-6cbd-492e-cf30-d2584b20a56e"
      },
      "id": "g0w2QZSD8yKD",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(1000, 150528)\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale data\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5cB2H7E9AuA",
        "outputId": "a2252000-b47e-4cc2-c471-5166c506f699"
      },
      "id": "k5cB2H7E9AuA",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PCA"
      ],
      "metadata": {
        "id": "lN2G80OL5KFL"
      },
      "id": "lN2G80OL5KFL"
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 2 components\n",
        "pca = PCA(n_components=2)\n",
        "X_train_2PC = np.asarray(pca.fit_transform(X_train))\n",
        "X_test_2PC = np.asarray(pca.transform(X_test))\n",
        "\n",
        "sns.scatterplot(x=X_train_2PC[:, 0], \n",
        "                y=X_train_2PC[:, 1],\n",
        "                hue=y_train_dx, \n",
        "                alpha=.3,\n",
        "                palette=sns.color_palette(\"colorblind\", 5))\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.title(\"Diabetic Retinopathy Plotted with PCA\")\n",
        "plt.legend(loc='upper right');\n"
      ],
      "metadata": {
        "id": "VqDpi8EE3C0W"
      },
      "id": "VqDpi8EE3C0W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression baseline with PCA\n",
        "baseline_lr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs')\n",
        "baseline_lr.fit(X_train_2PC, y_train_dx)\n",
        "\n",
        "score = baseline_lr.score(X_test_2PC, y_test_dx)\n",
        "print('Logistic Regresion PCA Baseline Score = ', score)"
      ],
      "metadata": {
        "id": "DSMYI0hZ30UA"
      },
      "id": "DSMYI0hZ30UA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Truncated SVD\n"
      ],
      "metadata": {
        "id": "lnOb955X5NG5"
      },
      "id": "lnOb955X5NG5"
    },
    {
      "cell_type": "code",
      "source": [
        "# truncated SVD\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "X_train_2d = svd.fit_transform(X_train)\n",
        "X_test_2d = svd.transform(X_test)\n",
        "\n",
        "print('X_train_2d', X_train_2d.shape)\n",
        "print('X_test_2d', X_test_2d.shape)"
      ],
      "metadata": {
        "id": "8iQgkHPG9AxY"
      },
      "id": "8iQgkHPG9AxY",
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot TruncatedSVD\n",
        "sns.set(style='white', rc={\"figure.figsize\":(10, 7)}, font_scale=1.3)\n",
        "sns.scatterplot(x=X_train_2d[:, 0], \n",
        "                y=X_train[:, 1],\n",
        "                hue=y_train_dx \n",
        "                alpha=.3,\n",
        "                palette=sns.color_palette(\"colorblind\", 5))\n",
        "plt.xlabel(\"SVD Component 1\")\n",
        "plt.ylabel(\"SVD Component 2\")\n",
        "plt.title(\"Diabetic Retinopathy Plotted with SVD\");\n",
        "plt.legend(loc='upper right');"
      ],
      "metadata": {
        "id": "sAPUy90C9A4I"
      },
      "id": "sAPUy90C9A4I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression baseline with SVD\n",
        "baseline_lr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs')\n",
        "baseline_lr.fit(X_train_2d, y_train_dx)\n",
        "\n",
        "score = baseline_lr.score(X_test_2d, y_train_dx)\n",
        "print('Logistic Regresion SVD Baseline Score = ', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk1EXzmg9A6g",
        "outputId": "02973a40-e719-46c6-8b5b-35675d716eb0"
      },
      "id": "Uk1EXzmg9A6g",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(multi_class='multinomial')"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Logistic regression scores poorly on accruacy for classifying diabetic retinopathy based on retinal images**"
      ],
      "metadata": {
        "id": "T5X-H2cdwxB4"
      },
      "id": "T5X-H2cdwxB4"
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mztWEiyk-cqO"
      },
      "id": "mztWEiyk-cqO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwlHbfpL1JAH"
      },
      "source": [
        "## 6 | Deep Learning Models"
      ],
      "id": "GwlHbfpL1JAH"
    },
    {
      "cell_type": "code",
      "source": [
        "# convert label to a 2D array with binary columnns for each class (one-hot encoding)\n",
        "y_train_dx_cat = to_categorical(y_train_dx)\n",
        "y_train_dx_cat"
      ],
      "metadata": {
        "id": "v8kvrPypxJAa"
      },
      "id": "v8kvrPypxJAa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Base CNN"
      ],
      "metadata": {
        "id": "oh0NfWeMwb4f"
      },
      "id": "oh0NfWeMwb4f"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
        "'''\n",
        " In this network structure, note that we follow the typical CNN heuristic of \n",
        " gradually reducing width and height dimenions over time with max pooling\n",
        " (typically by a factor of 2), but increasing the filter depth dimension \n",
        " to find increasingly specific patterns. These models are typically compromised \n",
        " of a series of convolutional blocks followed by a flattening operation and \n",
        " a series of fully connected layers at the terminus.\n",
        "'''\n",
        "\n",
        "NN = Sequential()\n",
        "\n",
        "NN.add(InputLayer(input_shape=X_train.shape[1:]))\n",
        "\n",
        "# Conv block 1.  You can add more conv steps to\n",
        "# each block to increase model capacity.\n",
        "NN.add(Conv2D(filters=10, kernel_size=3, activation='relu', padding='same'))\n",
        "# NN.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "NN.add(MaxPooling2D())\n",
        "\n",
        "# Conv block 2 - note we increase filter dimension as we move\n",
        "# further into the network. You can add more conv steps to\n",
        "# each block to increase model capacity.\n",
        "NN.add(Conv2D(filters=20, kernel_size=3, activation='relu', padding='same'))\n",
        "# NN.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "NN.add(MaxPooling2D())\n",
        "\n",
        "# Conv block 3 - The conv blocks should be ended with either a flatten\n",
        "# layer or a global pooling layer. These transform the 2D layers to 1D\n",
        "# to match the following dense layers.\n",
        "NN.add(Conv2D(filters=30, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "NN.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully connected block - flattening followed by dense and output layers\n",
        "# NN.add(Flatten())\n",
        "NN.add(Dense(20, activation='relu'))\n",
        "NN.add(Dense(10, activation='softmax'))  # 10 target classes\n",
        "\n",
        "NN.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "NN.summary()\n",
        "NN.fit(X_train, y_train_cat, epochs=5, verbose=1, validation_split=0.25,\n",
        "       callbacks=[\n",
        "           keras.callbacks.ModelCheckpoint(\n",
        "               'models/mnist.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "               save_best_only=True)\n",
        "       ])  # track progress as we fit"
      ],
      "metadata": {
        "id": "wnRwzshFDoAN"
      },
      "id": "wnRwzshFDoAN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(NN.predict(X_test), axis=1)\n",
        "accuracy_score(y_test, preds)"
      ],
      "metadata": {
        "id": "HD7tNv6HEPf0"
      },
      "id": "HD7tNv6HEPf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Apply transfer learning"
      ],
      "metadata": {
        "id": "8lRv9oq0DoXY"
      },
      "id": "8lRv9oq0DoXY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MobileNet"
      ],
      "metadata": {
        "id": "2nMXEjRZDq2f"
      },
      "id": "2nMXEjRZDq2f"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import mobilenet_v2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "def prepare_image(img_path):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = mobilenet_v2.preprocess_input(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "xrZGOUJRERuB"
      },
      "id": "xrZGOUJRERuB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "efFHMIzkEqaj"
      },
      "id": "efFHMIzkEqaj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is all we need to load and use the full pretrained model!\n",
        "model = mobilenet_v2.MobileNetV2(weights='imagenet',)\n",
        "\n",
        "x = prepare_image('dog.jpeg') #update this path if your image folder is in a different directory than the notebook!\n",
        "# df = pd.read_csv(io.BytesIO(\n",
        "#     uploaded['dog.jpeg']))\n",
        "# df.head()\n",
        "out = model.predict(x)\n",
        "\n",
        "print('Predicted:', mobilenet_v2.decode_predictions(out))"
      ],
      "metadata": {
        "id": "8IyEAb4uEa_c"
      },
      "id": "8IyEAb4uEa_c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "YPgyKoqgEt1j"
      },
      "id": "YPgyKoqgEt1j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = prepare_image('sloth.jpg')\n",
        "\n",
        "out = model.predict(x)\n",
        "\n",
        "print('Predicted:', mobilenet_v2.decode_predictions(out))"
      ],
      "metadata": {
        "id": "-pL4CX9kEgmg"
      },
      "id": "-pL4CX9kEgmg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(NN.predict(X_test), axis=1)\n",
        "accuracy_score(y_test, preds)"
      ],
      "metadata": {
        "id": "P0f4EbLKER1k"
      },
      "id": "P0f4EbLKER1k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "cBiUoVV6EwLS"
      },
      "id": "cBiUoVV6EwLS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transfer learning on pretrained base"
      ],
      "metadata": {
        "id": "icMUjUlSE6NY"
      },
      "id": "icMUjUlSE6NY"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# note we exclude the final dense layers by setting include_top=False,\n",
        "# and add new ones to train from scratch below\n",
        "base_model = mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)) \n",
        " \n",
        "# Freeze convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False    \n",
        "\n",
        "# Establish new fully connected block\n",
        "x = base_model.output\n",
        "x = Flatten()(x) # flatten from convolution tensor output \n",
        "x = Dense(100, activation='relu')(x) # number of layers and units are hyperparameters, as usual\n",
        "x = Dense(50, activation='relu')(x)\n",
        "predictions = Dense(5, activation='softmax')(x) # should match # of classes predicted\n",
        "\n",
        "# define formal model object to train and compile it as usual\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eQ7uzAnwE3SL"
      },
      "id": "eQ7uzAnwE3SL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i.e. if we had training images and our own labels, we could run\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "IbSgyTxuE3VU"
      },
      "id": "IbSgyTxuE3VU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LwFwAqupE3X4"
      },
      "id": "LwFwAqupE3X4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6miuOw2zE3af"
      },
      "id": "6miuOw2zE3af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G2dfnuYCE3dG"
      },
      "id": "G2dfnuYCE3dG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 | Model: Diagnosiing Diabetic Retinopathy"
      ],
      "metadata": {
        "id": "VMnQTUSnCkhn"
      },
      "id": "VMnQTUSnCkhn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Model"
      ],
      "metadata": {
        "id": "8fnbT33NC1pZ"
      },
      "id": "8fnbT33NC1pZ"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ikzTMTq2DDVT"
      },
      "id": "ikzTMTq2DDVT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "fuO9Cg9MC1zv"
      },
      "id": "fuO9Cg9MC1zv"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M1R27KSBDX89"
      },
      "id": "M1R27KSBDX89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report "
      ],
      "metadata": {
        "id": "dURaUJdqDK-W"
      },
      "id": "dURaUJdqDK-W"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-hRjThSJDR-N"
      },
      "id": "-hRjThSJDR-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "rfBOMQR1DQbO"
      },
      "id": "rfBOMQR1DQbO"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zO6sW_EcDV1B"
      },
      "id": "zO6sW_EcDV1B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  code snippets"
      ],
      "metadata": {
        "id": "R3hNmYbdp347"
      },
      "id": "R3hNmYbdp347"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### https://github.com/sdblass/Metis_coursework/blob/master/6_Deep_Learning/3_Basic_CNN.ipynb"
      ],
      "metadata": {
        "id": "NjAnXC9BAa29"
      },
      "id": "NjAnXC9BAa29"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code adapted from [ngoodby](https://github.com/ngoodby/Metis-Deep-Learning-Project/blob/master/model_creation.ipynb)"
      ],
      "metadata": {
        "id": "cmEQPzB4JLgt"
      },
      "id": "cmEQPzB4JLgt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code adapted from [PurpleGrace](https://github.com/PurpleGrace/Deep_Learning_Tools_Image_Classification/blob/main/code/1.EDA_Sample_Images.ipynb)"
      ],
      "metadata": {
        "id": "BotmqlFzK3Yv"
      },
      "id": "BotmqlFzK3Yv"
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_array(img_path):\n",
        "    img=  IMG.load_img(img_path,target_size=[150,150])\n",
        "    x = IMG.img_to_array(img)\n",
        "    return x"
      ],
      "metadata": {
        "id": "cq3lO9F4LoK2"
      },
      "id": "cq3lO9F4LoK2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = 'work_data'\n",
        "\n",
        "work_data_df = {'image_path':[],'category':[],'class':[]}\n",
        "\n",
        "for class_ in os.listdir(filepath):\n",
        "    if class_ != '.DS_Store':  \n",
        "        for category in os.listdir(filepath +\"/\"+class_):\n",
        "            if category != '.DS_Store':        \n",
        "                for image in os.listdir(filepath +\"/\"+class_ +\"/\"+category):\n",
        "                    if image != '.DS_Store':\n",
        "                        work_data_df['image_path'].append(filepath +\"/\"+class_+\"/\"+category+\"/\"+ image)\n",
        "                        work_data_df['category'].append(category)\n",
        "                        work_data_df['class'].append(class_)\n",
        "work_data_df = pd.DataFrame(work_data_df)    \n",
        "work_data_df.head()"
      ],
      "metadata": {
        "id": "EeE63urSLoOg"
      },
      "id": "EeE63urSLoOg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "work_data_df.to_csv('work_data_df')\n"
      ],
      "metadata": {
        "id": "QJw0JrevKwts"
      },
      "id": "QJw0JrevKwts",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "X_val = []\n",
        "X_test = []\n",
        "\n",
        "data_train = work_data_df[work_data_df['class'] == 'train']\n",
        "y_train = data_train.category.astype(\"category\").cat.codes\n",
        "y_train_hotcode = keras.utils.to_categorical(y_train)\n",
        "for index in data_train.index:\n",
        "    X_train.append(img_to_array(data_train.loc[index,'image_path']))\n",
        "    \n",
        "data_val = work_data_df[work_data_df['class'] == 'validation']\n",
        "y_val = data_val.category.astype(\"category\").cat.codes\n",
        "y_val_hotcode = keras.utils.to_categorical(y_train)\n",
        "for index in data_val.index:\n",
        "    X_val.append(img_to_array(data_val.loc[index,'image_path']))    \n",
        "    \n",
        "data_test = work_data_df[work_data_df['class'] == 'test']\n",
        "y_test = data_test.category.astype(\"category\").cat.codes\n",
        "y_test_hotcode = keras.utils.to_categorical(y_test)\n",
        "for index in data_test.index:\n",
        "    X_test.append(img_to_array((data_test.loc[index,'image_path'])))   \n",
        "    \n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_val = np.array(X_val)"
      ],
      "metadata": {
        "id": "Ot1g_eGVKw0_"
      },
      "id": "Ot1g_eGVKw0_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Save X_digit, y_digit\n",
        "image_data_array = (X_train, X_test,X_val,y_train,y_test,y_val)\n",
        "with open('image_data_array.pickle','wb') as file:\n",
        "    pickle.dump(image_data_array,file)"
      ],
      "metadata": {
        "id": "HBXzYqulLEeL"
      },
      "id": "HBXzYqulLEeL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"We have {len(X_train)} train dataset\")\n",
        "print(f\"We have {len(X_val)} train dataset\")\n",
        "print(f\"We have {len(X_test)} test dataset\")"
      ],
      "metadata": {
        "id": "CniW_FGpLEiG"
      },
      "id": "CniW_FGpLEiG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global category_map\n",
        "category_int_map = dict(zip(data_train.category,y_train))\n",
        "int_category_map = dict(zip(y_train,data_train.category))\n",
        "int_category_map"
      ],
      "metadata": {
        "id": "ne9ldw-HLEk8"
      },
      "id": "ne9ldw-HLEk8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_int_map\n"
      ],
      "metadata": {
        "id": "xlHC36jyLMZd"
      },
      "id": "xlHC36jyLMZd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = '/tmp/raw_data/test'\n",
        "validation_data_dir = '/tmp/raw_data/test'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "epochs = 50\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "2YcpKfoF3qwZ"
      },
      "id": "2YcpKfoF3qwZ",
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "metadata": {
        "id": "WBv-VnOP3qzS"
      },
      "id": "WBv-VnOP3qzS",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "FjzZk4kvH-Cu"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=X_train.shape[1:])))\n",
        "\n",
        "model.add(Conv2D(1000, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(750, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ],
      "id": "FjzZk4kvH-Cu"
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              optimizer='mse',\n",
        "              metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='rmsprop',\n",
        "#               metrics=['precision', 'recall'])"
      ],
      "metadata": {
        "id": "uxuBD5Zx3q6S"
      },
      "id": "uxuBD5Zx3q6S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/raw_data/train',  \n",
        "        target_size=(150, 150), \n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')  \n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/tmp/raw_data/test',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x2C2Sl5zyW2",
        "outputId": "0c32a2c4-f668-4967-b51e-c1aa77b92663"
      },
      "id": "1x2C2Sl5zyW2",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33725 images belonging to 5 classes.\n",
            "Found 12782 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=nb_train_samples // batch_size,\n",
        "        epochs=5,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=nb_validation_samples // batch_size\n",
        "        )\n",
        "\n",
        "model.save_weights('first_try.h5')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P_8jaBwzyfH",
        "outputId": "89626f7b-cdec-415c-a45b-61bfc4341a9c"
      },
      "id": "4P_8jaBwzyfH",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "125/125 [==============================] - 32s 145ms/step - loss: -21958856.0000 - accuracy: 0.1600 - val_loss: -114111040.0000 - val_accuracy: 0.1250\n",
            "Epoch 2/5\n",
            "125/125 [==============================] - 18s 141ms/step - loss: -546496128.0000 - accuracy: 0.1620 - val_loss: -1443959808.0000 - val_accuracy: 0.1513\n",
            "Epoch 3/5\n",
            "125/125 [==============================] - 16s 129ms/step - loss: -3837767680.0000 - accuracy: 0.1420 - val_loss: -7440918528.0000 - val_accuracy: 0.1750\n",
            "Epoch 4/5\n",
            "125/125 [==============================] - 16s 128ms/step - loss: -15062197248.0000 - accuracy: 0.1230 - val_loss: -24977846272.0000 - val_accuracy: 0.1675\n",
            "Epoch 5/5\n",
            "125/125 [==============================] - 17s 138ms/step - loss: -43709054976.0000 - accuracy: 0.1475 - val_loss: -67543609344.0000 - val_accuracy: 0.1437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Proliferate_DR', 'Mild','No_DR', 'Severe', 'Moderate']\n",
        "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "size = (224,224)\n",
        "num_classes = len(class_names)"
      ],
      "metadata": {
        "id": "bAlqoQeE4UfU"
      },
      "id": "bAlqoQeE4UfU",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(class_names):\n",
        "    \n",
        "    datasets = ['/tmp/raw_data/train', \n",
        "                '/tmp/raw_data/test']\n",
        "    output = []\n",
        "    \n",
        "    # Iterate through training and test set folders\n",
        "    for dataset in datasets:\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "        folders = os.listdir(dataset)\n",
        "        folders = [value for value in folders if value != \".DS_Store\"]\n",
        "        \n",
        "        print(\"Loading {}\".format(dataset))\n",
        "        \n",
        "        # Iterate through each folder corresponding to a category\n",
        "        for folder in folders:\n",
        "            label = class_names_label[folder]\n",
        "            \n",
        "            # Iterate through each image in the folder\n",
        "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
        "\n",
        "                # Get the path name of the image\n",
        "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
        "\n",
        "                # Open and resize the image\n",
        "                image = cv2.imread(img_path)\n",
        "#                 image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#                 image = cv2.resize(image, size) \n",
        "\n",
        "                # Append the image and its corresponding label to the output\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                \n",
        "        images = np.array(images, dtype = None)\n",
        "        labels = np.array(labels, dtype = None)   \n",
        "        \n",
        "        output.append((images, labels))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "x4VmTxXD4UrF"
      },
      "id": "x4VmTxXD4UrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = load_data(class_names)"
      ],
      "metadata": {
        "id": "20QnWkNP4Uxk"
      },
      "id": "20QnWkNP4Uxk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.flatten()\n",
        "print('train images type:', type(train_images))\n",
        "print('train images shape:', train_images.shape)"
      ],
      "metadata": {
        "id": "PRd0LN854U1f"
      },
      "id": "PRd0LN854U1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = test_images.flatten()\n",
        "print('test images type:', type(test_images))\n",
        "print('test images shape:', test_images.shape)"
      ],
      "metadata": {
        "id": "jR9Zamej4U6H"
      },
      "id": "jR9Zamej4U6H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R4_o3XEqAS-O"
      },
      "id": "R4_o3XEqAS-O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code source: https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d "
      ],
      "metadata": {
        "id": "Di9VDJ555WHh"
      },
      "id": "Di9VDJ555WHh"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XLR-rZUhBcDS",
        "k3K6dIVTA85Q",
        "OGGX9W-lzlMS",
        "RoEREXfi_1bd",
        "NTEDyxmg-dlV",
        "Sn8eVz_kgInL",
        "lN2G80OL5KFL",
        "lnOb955X5NG5",
        "GwlHbfpL1JAH",
        "VMnQTUSnCkhn",
        "R3hNmYbdp347",
        "BotmqlFzK3Yv"
      ],
      "machine_shape": "hm",
      "name": "dl-diabetic-retinopathy-model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (deep_learning)",
      "language": "python",
      "name": "deep_learning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}